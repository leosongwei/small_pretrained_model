{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BatchEncoding(input_ids=tensor([[    0,     0,     0,   264,   284,   277],\n",
       "        [30914, 30943, 30914, 30947, 30914, 30970]], dtype=torch.int32), attention_mask=tensor([[0, 0, 0, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1]], dtype=torch.int32))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glm3_tokenizer\n",
    "import torch\n",
    "\n",
    "from typing import Any, Union, List\n",
    "\n",
    "class CMMLUTokenizer:\n",
    "    def __init__(self, real_tokenizer: glm3_tokenizer.GLM3Tokenizer) -> None:\n",
    "        self._tokenizer = real_tokenizer\n",
    "\n",
    "    def encode(self, string: str, return_tensors=\"pt\"):\n",
    "        return self._tokenizer.encode_one_no_attn_no_special(string).tolist()\n",
    "    \n",
    "    def convert_tokens_to_ids(self, tokens: Union[str, List[str]]):\n",
    "        if isinstance(tokens, str):\n",
    "            tokens = [tokens]\n",
    "        \n",
    "        return [int(self._tokenizer.encode_one_no_attn_no_special(token)[0]) for token in tokens]\n",
    "    \n",
    "    def __call__(self, string, return_tensors=\"pt\") -> Any:\n",
    "        return self._tokenizer.encode(string, parse_special_tokens=False)\n",
    "\n",
    "_glm3_tokenizer = glm3_tokenizer.GLM3Tokenizer()\n",
    "cmmlu_tokenizer = CMMLUTokenizer(_glm3_tokenizer)\n",
    "cmmlu_tokenizer.convert_tokens_to_ids([\"A\", \"B\", \"C\", \"D\"])\n",
    "cmmlu_tokenizer([\"a b c\", \"1 2 3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import custom_model\n",
    "import os\n",
    "import safetensors.torch\n",
    "import torch\n",
    "\n",
    "config = custom_model.CustomModelConfig(\n",
    "            vocab_size=_glm3_tokenizer.vocab_size(),\n",
    "            padding_token_id=_glm3_tokenizer.token_pad_id,\n",
    "            max_position_embeddings=4096,\n",
    "            hidden_size=704,\n",
    "            num_heads=16,\n",
    "            MLP_intermediate=5000,\n",
    "            num_layers=28,\n",
    "            attention_dropout=0.1,\n",
    "            dtype=torch.bfloat16,\n",
    "            training=True,\n",
    "            linear_imp = torch.nn.Linear\n",
    "        )\n",
    "\n",
    "model = custom_model.CustomLLamaModel(config).to(device='cuda')\n",
    "model_dir = r\"/mnt/sata2tb/leo/NLP/small_pretrained_model/saves_medium/checkpoint-751346922-751.35M\"\n",
    "model_path = os.path.join(model_dir, \"model.safetensor\")\n",
    "safetensors.torch.load_model(model, model_path)\n",
    "model.eval()\n",
    "\n",
    "encoded_inputs = _glm3_tokenizer.encode(\"奥运冠军\").to('cuda')\n",
    "model_out = model(**encoded_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import CMMLU.mp_utils\n",
    "from CMMLU.mp_utils import choices, format_example, gen_prompt, softmax\n",
    "# from CMMLU.hf_causal_model import eval\n",
    "from typing import Any\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "\n",
    "#def eval(model, tokenizer, subject, dev_df, test_df, num_few_shot, max_length, cot):\n",
    "# def eval(*args, **kwargs):\n",
    "#     print(repr(args))\n",
    "#     #print(repr(kwargs))\n",
    "#     for k, v in kwargs.items():\n",
    "#         print(f\"{k}: {type(v)}\")\n",
    "\n",
    "# model: <class 'NoneType'>\n",
    "# tokenizer: <class 'NoneType'>\n",
    "# subject: <class 'str'>\n",
    "# dev_df: <class 'pandas.core.frame.DataFrame'>\n",
    "# test_df: <class 'pandas.core.frame.DataFrame'>\n",
    "# num_few_shot: <class 'int'>\n",
    "# max_length: <class 'int'>\n",
    "# cot: <class 'bool'>\n",
    "def eval(\n",
    "        model: Any,\n",
    "        tokenizer: Any,\n",
    "        subject: str,\n",
    "        dev_df: DataFrame,\n",
    "        test_df: DataFrame,\n",
    "        num_few_shot: int,\n",
    "        max_length: int,\n",
    "        cot: bool # not used\n",
    "        ):\n",
    "    choice_ids = [tokenizer.convert_tokens_to_ids(choice) for choice in CMMLU.mp_utils.choices]\n",
    "    cors = []\n",
    "    all_conf = [] # confidence\n",
    "    all_preds = [] # predicates\n",
    "    answers = CMMLU.mp_utils.choices[: test_df.shape[1] - 2]\n",
    "\n",
    "    batch_size = 10\n",
    "    bucket = []\n",
    "    def run_and_cleanup_bucket():\n",
    "        nonlocal bucket\n",
    "        prompts = [prompt for prompt, label in bucket]\n",
    "        labels = [label for prompt, label in bucket]\n",
    "        bucket = []\n",
    "\n",
    "        inputs = tokenizer(prompts).to(\"cuda\")\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            last_token_logits = outputs[:, -1, :] # shape: [bz, vocab_size]\n",
    "\n",
    "\n",
    "    for i in range(test_df.shape[0]):\n",
    "        prompt_end = format_example(test_df, i, subject, include_answer=False)\n",
    "        prompt = gen_prompt(dev_df=dev_df,\n",
    "                            subject=subject,\n",
    "                            prompt_end=prompt_end,\n",
    "                            num_few_shot=num_few_shot,\n",
    "                            tokenizer=tokenizer,\n",
    "                            max_length=max_length)\n",
    "        label = test_df.iloc[i, test_df.shape[1] - 1]\n",
    "        bucket.append((prompt, label))\n",
    "\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "        if \"token_type_ids\" in inputs: # For Falcon\n",
    "            inputs.pop(\"token_type_ids\")\n",
    "        \n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            last_token_logits = outputs[:, -1, :]\n",
    "            choice_logits = last_token_logits[:, choice_ids].detach().to(device='cpu', dtype=torch.float32).numpy()\n",
    "            conf = softmax(choice_logits[0])[choices.index(label)]\n",
    "            pred = {0: \"A\", 1: \"B\", 2: \"C\", 3: \"D\"}[np.argmax(choice_logits[0])]\n",
    "\n",
    "            print(f\"choice_logits: {choice_logits.shape}\")\n",
    "            print(f\"conf({type(conf)}): {conf}\")\n",
    "            print(f\"pred({type(pred)}): {pred}\")\n",
    "\n",
    "        all_preds += pred\n",
    "        all_conf.append(conf)\n",
    "        cors.append(pred == label)\n",
    "\n",
    "        print(f\"all_preds: {all_preds}\")\n",
    "        print(f\"all_conf: {all_conf}\")\n",
    "        print(f\"cors: {cors}\")\n",
    "        raise ValueError(\"hmm\")\n",
    "\n",
    "    acc = np.mean(cors)\n",
    "    print(\"Average accuracy {:.3f} - {}\".format(acc, subject))\n",
    "    return acc, all_preds, all_conf\n",
    "\n",
    "    # print(\"answers\", answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers.models.llama.modeling_llama import LlamaForCausalLM, LlamaConfig, LlamaModel, LlamaRotaryEmbedding\n",
    "# from transformers import AutoTokenizer, AutoModel\n",
    "# import transformers\n",
    "# import torch\n",
    "\n",
    "# # src/transformers/models/llama/modeling_llama.py\n",
    "\n",
    "# LLAMA_PATH = '/home/leo/NLP/models/llama/Llama-2-7b-hf'\n",
    "# tokenizer = AutoTokenizer.from_pretrained(LLAMA_PATH, trust_remote_code=True)\n",
    "# # model = LlamaForCausalLM.from_pretrained(LLAMA_PATH, attn_implementation=\"eager\", torch_dtype=torch.float16).to(\"cuda\")\n",
    "# # model.eval()\n",
    "\n",
    "# import CMMLU.mp_utils\n",
    "\n",
    "# choice_ids = [tokenizer.convert_tokens_to_ids(choice) for choice in CMMLU.mp_utils.choices]\n",
    "# print(choice_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "choice_logits: (1, 4, 1)\n",
      "conf(<class 'numpy.ndarray'>): [0.7707439]\n",
      "pred(<class 'str'>): B\n",
      "all_preds: ['B']\n",
      "all_conf: [array([0.7707439], dtype=float32)]\n",
      "cors: [True]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "hmm",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 17\u001b[0m\n\u001b[1;32m     13\u001b[0m parser\u001b[38;5;241m.\u001b[39madd_argument(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--cot\u001b[39m\u001b[38;5;124m\"\u001b[39m, action\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstore_true\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     14\u001b[0m args \u001b[38;5;241m=\u001b[39m parser\u001b[38;5;241m.\u001b[39mparse_args([])\n\u001b[0;32m---> 17\u001b[0m \u001b[43mCMMLU\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmp_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_eval\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcmmlu_tokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43meval\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/sata2tb/leo/NLP/small_pretrained_model/CMMLU/mp_utils.py:96\u001b[0m, in \u001b[0;36mrun_eval\u001b[0;34m(model, tokenizer, eval, args)\u001b[0m\n\u001b[1;32m     93\u001b[0m dev_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(args\u001b[38;5;241m.\u001b[39mdata_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdev\u001b[39m\u001b[38;5;124m\"\u001b[39m, subject \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m), header\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     94\u001b[0m test_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(args\u001b[38;5;241m.\u001b[39mdata_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m, subject \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m), header\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 96\u001b[0m acc, preds, confs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43meval\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m                         \u001b[49m\u001b[43msubject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubject\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mdev_df\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdev_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mtest_df\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mnum_few_shot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_few_shot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mcot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcot\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcot\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m test_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m preds\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwith_conf\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m args \u001b[38;5;129;01mand\u001b[39;00m args\u001b[38;5;241m.\u001b[39mwith_conf:\n",
      "Cell \u001b[0;32mIn[7], line 80\u001b[0m, in \u001b[0;36meval\u001b[0;34m(model, tokenizer, subject, dev_df, test_df, num_few_shot, max_length, cot)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall_conf: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mall_conf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcors: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcors\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 80\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhmm\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     82\u001b[0m acc \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(cors)\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAverage accuracy \u001b[39m\u001b[38;5;132;01m{:.3f}\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(acc, subject))\n",
      "\u001b[0;31mValueError\u001b[0m: hmm"
     ]
    }
   ],
   "source": [
    "import CMMLU.hf_causal_model\n",
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--model_name_or_path\", type=str, default=\"\")\n",
    "parser.add_argument(\"--lora_weights\", type=str, default=\"\")\n",
    "parser.add_argument(\"--data_dir\", type=str, default=\"CMMLU/data\")\n",
    "parser.add_argument(\"--save_dir\", type=str, default=\"CMMLU/results/not_specified\")\n",
    "parser.add_argument(\"--num_few_shot\", type=int, default=0)\n",
    "parser.add_argument(\"--max_length\", type=int, default=2048)\n",
    "parser.add_argument(\"--load_in_8bit\", action='store_true')\n",
    "parser.add_argument(\"--with_conf\", action='store_true')\n",
    "parser.add_argument(\"--cot\", action='store_true')\n",
    "args = parser.parse_args([])\n",
    "\n",
    "\n",
    "CMMLU.mp_utils.run_eval(\n",
    "    model, cmmlu_tokenizer,\n",
    "    eval,\n",
    "    args\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Average accuracy 0.272 - agronomy\n",
    "Average accuracy 0.270 - anatomy\n",
    "Average accuracy 0.232 - ancient_chinese\n",
    "Average accuracy 0.269 - arts\n",
    "Average accuracy 0.236 - astronomy\n",
    "Average accuracy 0.287 - business_ethics\n",
    "Average accuracy 0.263 - chinese_civil_service_exam\n",
    "Average accuracy 0.229 - chinese_driving_rule\n",
    "Average accuracy 0.257 - chinese_food_culture\n",
    "Average accuracy 0.271 - chinese_foreign_policy\n",
    "Average accuracy 0.254 - chinese_history\n",
    "Average accuracy 0.255 - chinese_literature\n",
    "Average accuracy 0.274 - chinese_teacher_qualification\n",
    "Average accuracy 0.241 - clinical_knowledge\n",
    "Average accuracy 0.283 - college_actuarial_science\n",
    "Average accuracy 0.299 - college_education\n",
    "Average accuracy 0.283 - college_engineering_hydrology\n",
    "Average accuracy 0.259 - college_law\n",
    "Average accuracy 0.229 - college_mathematics\n",
    "Average accuracy 0.198 - college_medical_statistics\n",
    "Average accuracy 0.267 - college_medicine\n",
    "Average accuracy 0.240 - computer_science\n",
    "Average accuracy 0.246 - computer_security\n",
    "Average accuracy 0.252 - conceptual_physics\n",
    "Average accuracy 0.209 - construction_project_management\n",
    "Average accuracy 0.258 - economics\n",
    "Average accuracy 0.270 - education\n",
    "Average accuracy 0.250 - electrical_engineering\n",
    "Average accuracy 0.262 - elementary_chinese\n",
    "Average accuracy 0.237 - elementary_commonsense\n",
    "Average accuracy 0.273 - elementary_information_and_technology\n",
    "Average accuracy 0.283 - elementary_mathematics\n",
    "Average accuracy 0.289 - ethnology\n",
    "Average accuracy 0.287 - food_science\n",
    "Average accuracy 0.250 - genetics\n",
    "Average accuracy 0.242 - global_facts\n",
    "Average accuracy 0.254 - high_school_biology\n",
    "Average accuracy 0.311 - high_school_chemistry\n",
    "Average accuracy 0.229 - high_school_geography\n",
    "Average accuracy 0.268 - high_school_mathematics\n",
    "Average accuracy 0.255 - high_school_physics\n",
    "Average accuracy 0.252 - high_school_politics\n",
    "Average accuracy 0.246 - human_sexuality\n",
    "Average accuracy 0.222 - international_law\n",
    "Average accuracy 0.250 - journalism\n",
    "Average accuracy 0.234 - jurisprudence\n",
    "Average accuracy 0.299 - legal_and_moral_basis\n",
    "Average accuracy 0.301 - logical\n",
    "Average accuracy 0.295 - machine_learning\n",
    "Average accuracy 0.267 - management\n",
    "Average accuracy 0.300 - marketing\n",
    "Average accuracy 0.243 - marxist_theory\n",
    "Average accuracy 0.284 - modern_chinese\n",
    "Average accuracy 0.228 - nutrition\n",
    "Average accuracy 0.229 - philosophy\n",
    "Average accuracy 0.211 - professional_accounting\n",
    "Average accuracy 0.227 - professional_law\n",
    "Average accuracy 0.258 - professional_medicine\n",
    "Average accuracy 0.254 - professional_psychology\n",
    "Average accuracy 0.299 - public_relations\n",
    "Average accuracy 0.274 - security_study\n",
    "Average accuracy 0.239 - sociology\n",
    "Average accuracy 0.230 - sports_science\n",
    "Average accuracy 0.216 - traditional_chinese_medicine\n",
    "Average accuracy 0.254 - virology\n",
    "Average accuracy 0.230 - world_history\n",
    "Average accuracy 0.200 - world_religions\n",
    "STEM                                     25.95\n",
    "Humanities                               24.34\n",
    "Social Science                           26.46\n",
    "Other                                    24.92\n",
    "China specific                           25.22\n",
    "Overall                        25.57"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
